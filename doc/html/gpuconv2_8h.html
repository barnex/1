<!-- This comment will put IE 6, 7 and 8 in quirks mode -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>GPU_simulations: gpuconv2.h File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javaScript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body onload='searchBox.OnSelectItem(0);'>
<!-- Generated by Doxygen 1.6.3 -->
<script type="text/javascript"><!--
var searchBox = new SearchBox("searchBox", "search",false,'Search');
--></script>
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="annotated.html"><span>Data&nbsp;Structures</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <img id="MSearchSelect" src="search/search.png"
             onmouseover="return searchBox.OnSearchSelectShow()"
             onmouseout="return searchBox.OnSearchSelectHide()"
             alt=""/>
        <input type="text" id="MSearchField" value="Search" accesskey="S"
             onfocus="searchBox.OnSearchFieldFocus(true)" 
             onblur="searchBox.OnSearchFieldFocus(false)" 
             onkeyup="searchBox.OnSearchFieldChange(event)"/>
        <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
        </div>
      </li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li><a href="files.html"><span>File&nbsp;List</span></a></li>
      <li><a href="globals.html"><span>Globals</span></a></li>
    </ul>
  </div>
</div>
<div class="contents">
<h1>gpuconv2.h File Reference</h1><code>#include &quot;<a class="el" href="tensor_8h_source.html">tensor.h</a>&quot;</code><br/>
<code>#include &quot;<a class="el" href="gputil_8h_source.html">gputil.h</a>&quot;</code><br/>
<code>#include &lt;cufft.h&gt;</code><br/>
<code>#include &quot;<a class="el" href="gpufft2_8h_source.html">gpufft2.h</a>&quot;</code><br/>

<p><a href="gpuconv2_8h_source.html">Go to the source code of this file.</a></p>
<table border="0" cellpadding="0" cellspacing="0">
<tr><td colspan="2"><h2>Data Structures</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">struct &nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="structgpuconv2.html">gpuconv2</a></td></tr>
<tr><td colspan="2"><h2>Functions</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="structgpuconv2.html">gpuconv2</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="gpuconv2_8h.html#a276cde10877794d8927911fe2abeec0f">new_gpuconv2</a> (int *size, int *kernelSize)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="gpuconv2_8h.html#a517ed453bc81ab528138f9d7624efffe">gpuconv2_loadkernel5DSymm</a> (<a class="el" href="structgpuconv2.html">gpuconv2</a> *conv, <a class="el" href="structtensor.html">tensor</a> *kernel5D)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="gpuconv2_8h.html#a9846e091be7ddd707f1325cd50d0c455">gpuconv2_loadkernel2DSymm</a> (<a class="el" href="structgpuconv2.html">gpuconv2</a> *conv, <a class="el" href="structtensor.html">tensor</a> *kernel2D)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="gpuconv2_8h.html#ada13dcbed7b84f58bafbf2a0bc57ae85">gpuconv2_exec</a> (<a class="el" href="structgpuconv2.html">gpuconv2</a> *plan, <a class="el" href="structtensor.html">tensor</a> *source, <a class="el" href="structtensor.html">tensor</a> *dest)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="gpuconv2_8h.html#ac011c1c90f174de0957253c215a14e57">gpuconv2_loadkernel</a> (<a class="el" href="structgpuconv2.html">gpuconv2</a> *plan, <a class="el" href="structtensor.html">tensor</a> *kernel)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="gpuconv2_8h.html#a6fbd8e2f7bceed3b1c88b22c93fbc7f9">gpu_kernel_mul2</a> (float *ft_m_i, float *ft_kernel_comp_ij, float *ft_h_comp_j, int nRealNumbers)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="gpuconv2_8h.html#ac7cea8323497b8202392c49c909b6803">gpu_kernel_mul_complex_inplace_symm</a> (float *fftMx, float *fftMy, float *fftMz, float *fftKxx, float *fftKyy, float *fftKzz, float *fftKyz, float *fftKxz, float *fftKxy, int nRealNumbers)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="gpuconv2_8h.html#a2df60637926ff063cab034ec68d0dae5">gpuconv2_copy_pad</a> (<a class="el" href="structgpuconv2.html">gpuconv2</a> *conv, float *source, float *dest)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="gpuconv2_8h.html#a16e5077d5fca74094114eff78e98ea5a">gpuconv2_copy_unpad</a> (<a class="el" href="structgpuconv2.html">gpuconv2</a> *conv, float *source, float *dest)</td></tr>
</table>
<hr/><a name="_details"></a><h2>Detailed Description</h2>
<p>A smarter vector convolution plan on the GPU: real-to-complex FFT's. The redundant zero's in the padded magnetization buffers are ignored. The zero's in the micromagnetic kernel are ignored. Care is taken to align CUDA memory access.</p>
<p>The interface is flexible: gpuconv2_exec(m, h) can be called on any magnetization and field array that match the size of the plan. m and h are thus not stored in the plan itself. This is handy for higher order solvers that keep multiple versions of m and h.</p>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000006">Todo:</a></b></dt><dd>TODO voor convolutie (Ben)</dd></dl>
<p>1. Greense functies -&gt; dienen gegenereerd te worden in strided formaat -&gt; is symmetrische rank 4 tensor (vb: gxy = gyx, gxz = gzx, ..., slechts 2/3 van geheugen nodig) -&gt; Enkel reeel deel in Fourier domein (halveert geheugen vereisten) -&gt; implementatie algemene Greense tensor nodig met als input te gebruiken Greense functie -&gt; Er dient rekening gehouden te worden met mogelijke periodiciteit</p>
<p>2. seriele berekening veldwaarden gunstiger -&gt; beter seriele berekening van H_x, H_y, H_z als a. H^FFT = g^FFT_xx* m^FFT_x + g^FFT_xy* m^FFT_y + g^FFT_xz* m^FFT_z b. H_x = inv_FFT(H^FFT) c. H^FFT = g^FFT_xy* m^FFT_x + g^FFT_yy* m^FFT_y + g^FFT_yz* m^FFT_z d. H_y = inv_FFT(H^FFT) e. H^FFT = g^FFT_xz* m^FFT_x + g^FFT_yz* m^FFT_y + g^FFT_zz* m^FFT_z f. H_z = inv_FFT(H^FFT) Op die manier enkel geheugen nodig voor H^FFT (en niet voor elke component H^FFT_x, H^FFT_y, H^FFT_z) Antw: Ik denk dat ik nu slechts even veel geheugen gebruik: Ik houd 3 H^FFT componenten in het geheugen, maar slechts één m^FFT component, jij één H^FFT maar 3 m^FFT's. Of heb ik het mis op? (Arne.) Opm: misschien kunnen we wel één buffer uitsparen door eerst alle m_i te FFT-en en dan een "in-place" kernel vermenigvuldiging te doen. Per element wordt dan m_x[i], m_y[i], m_z[i] gebufferd in locale variablen, daarna wordt m^FFT element per element overschreven door H^FFT...</p>
<p>-&gt; H^FFT dient dezelfde dimensies te hebben als andere strided FFT tensoren</p>
<p>3. Transponeren matrices -&gt; is versnelling mogelijk door nullen niet te transponeren? -&gt; In place transponeren</p>
<p>4. Omtrent de FFT routines -&gt; Waarschijnlijk beter om FFT routines in een aparte bibliotheek te steken wegens mogelijk gebruik in andere convoluties -&gt; implementatie 2D varianten: Uitbreiding van de huidige routines of aparte routines? mogelijkheden: a. Aparte routines voor 3D en 2D: bij aanroepen if constructies nodig (if 3D, if 2D) b. uitbreiding routines:</p>
<ul>
<li>extra argument 2D of 3D, met daarna daarna twee totaal verschillende code blokken</li>
<li>geen extra argumenten, maar op basis van dimensies in argument.</li>
</ul>
<dl class="see"><dt><b>See also:</b></dt><dd><a class="el" href="structgpuconv1.html">gpuconv1</a>, <a class="el" href="gpuconv2_8h.html#a276cde10877794d8927911fe2abeec0f">new_gpuconv2</a>, <a class="el" href="gpuconv2_8h.html#ada13dcbed7b84f58bafbf2a0bc57ae85">gpuconv2_exec</a></dd></dl>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000007">Todo:</a></b></dt><dd>when NO=1, gxy and gxz are zero</dd></dl>
<dl class="author"><dt><b>Author:</b></dt><dd>Arne Vansteenkiste </dd>
<dd>
Ben Van de Wiele </dd></dl>
<hr/><h2>Function Documentation</h2>
<a class="anchor" id="a6fbd8e2f7bceed3b1c88b22c93fbc7f9"></a><!-- doxytag: member="gpuconv2.h::gpu_kernel_mul2" ref="a6fbd8e2f7bceed3b1c88b22c93fbc7f9" args="(float *ft_m_i, float *ft_kernel_comp_ij, float *ft_h_comp_j, int nRealNumbers)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gpu_kernel_mul2 </td>
          <td>(</td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>ft_m_i</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>ft_kernel_comp_ij</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>ft_h_comp_j</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>nRealNumbers</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Pointwise multiplication of arrays of complex numbers. ft_h_comp_j += ft_m_i * ft_kernel_comp_ij. Runs on the GPU. Makes use of kernel symmetry </p>
<dl class="note"><dt><b>Note:</b></dt><dd>DO NOT store in texture memory! This would be a bit faster on older devices, but actually slower on Fermi cards! </dd></dl>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>ft_m_i</em>&nbsp;</td><td>multiplication input 1 </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>ft_kernel_comp_ij</em>&nbsp;</td><td>multiplication input 2 </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>ft_h_comp_j</em>&nbsp;</td><td>multiplication result gets added to this array </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>nRealNumbers</em>&nbsp;</td><td>the number of floats(!) in each of the arrays, thus twice the number of complex's in them. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ac7cea8323497b8202392c49c909b6803"></a><!-- doxytag: member="gpuconv2.h::gpu_kernel_mul_complex_inplace_symm" ref="ac7cea8323497b8202392c49c909b6803" args="(float *fftMx, float *fftMy, float *fftMz, float *fftKxx, float *fftKyy, float *fftKzz, float *fftKyz, float *fftKxz, float *fftKxy, int nRealNumbers)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gpu_kernel_mul_complex_inplace_symm </td>
          <td>(</td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>fftMx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>fftMy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>fftMz</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>fftKxx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>fftKyy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>fftKzz</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>fftKyz</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>fftKxz</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>fftKxy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>nRealNumbers</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p><b>For internal use only.</b></p>

</div>
</div>
<a class="anchor" id="a2df60637926ff063cab034ec68d0dae5"></a><!-- doxytag: member="gpuconv2.h::gpuconv2_copy_pad" ref="a2df60637926ff063cab034ec68d0dae5" args="(gpuconv2 *conv, float *source, float *dest)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gpuconv2_copy_pad </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structgpuconv2.html">gpuconv2</a> *&nbsp;</td>
          <td class="paramname"> <em>conv</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>source</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>dest</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p><b>For internal use only.</b></p>
<p>Copies 3D data to a zero-padded, strided destination. Runs on the GPU. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>conv</em>&nbsp;</td><td>this convolution plan contains the sizes of both arrays </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>source</em>&nbsp;</td><td>source data on GPU, should have size: conv-&gt;size </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>dest</em>&nbsp;</td><td>destination data on GPU, should have size: conv-&gt;paddedStorageSize </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a16e5077d5fca74094114eff78e98ea5a"></a><!-- doxytag: member="gpuconv2.h::gpuconv2_copy_unpad" ref="a16e5077d5fca74094114eff78e98ea5a" args="(gpuconv2 *conv, float *source, float *dest)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gpuconv2_copy_unpad </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structgpuconv2.html">gpuconv2</a> *&nbsp;</td>
          <td class="paramname"> <em>conv</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>source</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *&nbsp;</td>
          <td class="paramname"> <em>dest</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p><b>For internal use only.</b></p>
<p>Copies 3D data from a zero-padded and strided destination. Runs on the GPU </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>conv</em>&nbsp;</td><td>this convolution plan contains the sizes of both arrays </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>source</em>&nbsp;</td><td>destination data on GPU, should have size: conv-&gt;paddedStorageSize </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>dest</em>&nbsp;</td><td>source data on GPU, should have size: conv-&gt;size </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ada13dcbed7b84f58bafbf2a0bc57ae85"></a><!-- doxytag: member="gpuconv2.h::gpuconv2_exec" ref="ada13dcbed7b84f58bafbf2a0bc57ae85" args="(gpuconv2 *plan, tensor *source, tensor *dest)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gpuconv2_exec </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structgpuconv2.html">gpuconv2</a> *&nbsp;</td>
          <td class="paramname"> <em>plan</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structtensor.html">tensor</a> *&nbsp;</td>
          <td class="paramname"> <em>source</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structtensor.html">tensor</a> *&nbsp;</td>
          <td class="paramname"> <em>dest</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Executes the convolution plan: convolves the source data with the stored kernel and stores the result in the destination pointer. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>plan</em>&nbsp;</td><td>the plan to execute </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>source</em>&nbsp;</td><td>the input vector field (magnetization) </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>dest</em>&nbsp;</td><td>the destination vector field (magnetic field) to store the result in </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ac011c1c90f174de0957253c215a14e57"></a><!-- doxytag: member="gpuconv2.h::gpuconv2_loadkernel" ref="ac011c1c90f174de0957253c215a14e57" args="(gpuconv2 *plan, tensor *kernel)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gpuconv2_loadkernel </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structgpuconv2.html">gpuconv2</a> *&nbsp;</td>
          <td class="paramname"> <em>plan</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structtensor.html">tensor</a> *&nbsp;</td>
          <td class="paramname"> <em>kernel</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Loads a kernel. Automatically called during <a class="el" href="gpuconv2_8h.html#a276cde10877794d8927911fe2abeec0f">new_gpuconv2()</a>, but could be used to change the kernel afterwards. </p>
<dl class="see"><dt><b>See also:</b></dt><dd><a class="el" href="gpuconv2_8h.html#a276cde10877794d8927911fe2abeec0f">new_gpuconv2</a> </dd></dl>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>plan</em>&nbsp;</td><td>plan to load the kernel into </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>kernel</em>&nbsp;</td><td>kernel to load (should match the plan size) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a9846e091be7ddd707f1325cd50d0c455"></a><!-- doxytag: member="gpuconv2.h::gpuconv2_loadkernel2DSymm" ref="a9846e091be7ddd707f1325cd50d0c455" args="(gpuconv2 *conv, tensor *kernel2D)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gpuconv2_loadkernel2DSymm </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structgpuconv2.html">gpuconv2</a> *&nbsp;</td>
          <td class="paramname"> <em>conv</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structtensor.html">tensor</a> *&nbsp;</td>
          <td class="paramname"> <em>kernel2D</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Loads a kernel into the convolution. The kernel is FFTed and stored in a 2-dimensional format: Kernel[SourceDir][index]. The kernel has the format discribed in <a class="el" href="gpukernel1_8h.html">gpukernel1.h</a> </p>
<dl class="see"><dt><b>See also:</b></dt><dd><a class="el" href="gpukernel1_8h.html">gpukernel1.h</a> </dd></dl>
<dl class="note"><dt><b>Note:</b></dt><dd>for use with Ben's kernels </dd></dl>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000008">Todo:</a></b></dt><dd>not yet implemented </dd></dl>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>kernel2D</em>&nbsp;</td><td>Kernel on Device, normalized </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a517ed453bc81ab528138f9d7624efffe"></a><!-- doxytag: member="gpuconv2.h::gpuconv2_loadkernel5DSymm" ref="a517ed453bc81ab528138f9d7624efffe" args="(gpuconv2 *conv, tensor *kernel5D)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void gpuconv2_loadkernel5DSymm </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structgpuconv2.html">gpuconv2</a> *&nbsp;</td>
          <td class="paramname"> <em>conv</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structtensor.html">tensor</a> *&nbsp;</td>
          <td class="paramname"> <em>kernel5D</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Loads a kernel into the convolution. The kernel is not yet FFTed and stored in the 5-dimensional format: Kernel[SourceDir][DestDir][X][Y][Z]. The kernel is assumed to be symmetric in the first two indices. </p>
<dl class="note"><dt><b>Note:</b></dt><dd>for use with Arne's kernels. </dd></dl>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>kernel5D</em>&nbsp;</td><td>Kernel on Host, not yet normalized </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a276cde10877794d8927911fe2abeec0f"></a><!-- doxytag: member="gpuconv2.h::new_gpuconv2" ref="a276cde10877794d8927911fe2abeec0f" args="(int *size, int *kernelSize)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structgpuconv2.html">gpuconv2</a>* new_gpuconv2 </td>
          <td>(</td>
          <td class="paramtype">int *&nbsp;</td>
          <td class="paramname"> <em>size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int *&nbsp;</td>
          <td class="paramname"> <em>kernelSize</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>New convolution plan with given size of the source vector field and kernel. If the kernel size is larger than the vector field, the field is zero-padded in the respective dimension to fit the size of the kernel. </p>
<dl class="note"><dt><b>Note:</b></dt><dd>After construction, a kernel should still be loaded. </dd></dl>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>size</em>&nbsp;</td><td>X Y and Z size of the magnetization vector field </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>kernelSize</em>&nbsp;</td><td>convolution kernel size of at least the size of the vector field </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
</div>
<!--- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&nbsp;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&nbsp;</span>Data Structures</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&nbsp;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&nbsp;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&nbsp;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&nbsp;</span>Defines</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<hr class="footer"/><address style="text-align: right;"><small>Generated on Tue Jul 6 16:19:19 2010 for GPU_simulations by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.3 </small></address>
</body>
</html>
