\hypertarget{gpuconv1_8h}{
\section{gpuconv1.h File Reference}
\label{gpuconv1_8h}\index{gpuconv1.h@{gpuconv1.h}}
}
{\ttfamily \#include \char`\"{}tensor.h\char`\"{}}\par
{\ttfamily \#include \char`\"{}gputil.h\char`\"{}}\par
{\ttfamily \#include $<$cufft.h$>$}\par
\subsection*{Data Structures}
\begin{DoxyCompactItemize}
\item 
struct \hyperlink{structgpuc2cplan}{gpuc2cplan}
\item 
struct \hyperlink{structgpuconv1}{gpuconv1}
\end{DoxyCompactItemize}
\subsection*{Defines}
\begin{DoxyCompactItemize}
\item 
\#define \hyperlink{gpuconv1_8h_a6ddfdda7a062d10cff4a72b76b44aeb8}{FORWARD}~CUFFT\_\-FORWARD
\item 
\#define \hyperlink{gpuconv1_8h_ade269cc47cfaba70068f2586e898051d}{INVERSE}~CUFFT\_\-INVERSE
\end{DoxyCompactItemize}
\subsection*{Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{structgpuc2cplan}{gpuc2cplan} $\ast$ \hyperlink{gpuconv1_8h_a7f9fff8937542904f3822c36dc968519}{new\_\-gpuc2cplan} (int \hyperlink{gpufft2__test_8cpp_a1a345a1e634b1d40f23b3333f3696366}{N0}, int \hyperlink{gpufft2__test_8cpp_a5a6a26e0827f9640d2eb7201017f19d7}{N1}, int \hyperlink{gpufft2__test_8cpp_adeea8075a0038c985c63d45161804d60}{N2})
\item 
void \hyperlink{gpuconv1_8h_aa6c8d327b2dda097866d1a520ca29845}{gpuc2cplan\_\-exec} (\hyperlink{structgpuc2cplan}{gpuc2cplan} $\ast$plan, float $\ast$data, int direction)
\item 
void \hyperlink{gpuconv1_8h_a2b2b2adffd7de89165c17057066d018a}{delete\_\-gpuc2cplan} (\hyperlink{structgpuc2cplan}{gpuc2cplan} $\ast$plan)
\item 
\hyperlink{structgpuconv1}{gpuconv1} $\ast$ \hyperlink{gpuconv1_8h_ac4cd0375594d902676a22b2d24b2d69c}{new\_\-gpuconv1} (int \hyperlink{gpufft2__test_8cpp_a1a345a1e634b1d40f23b3333f3696366}{N0}, int \hyperlink{gpufft2__test_8cpp_a5a6a26e0827f9640d2eb7201017f19d7}{N1}, int \hyperlink{gpufft2__test_8cpp_adeea8075a0038c985c63d45161804d60}{N2}, \hyperlink{structtensor}{tensor} $\ast$kernel)
\item 
void \hyperlink{gpuconv1_8h_a290a0200b1639a156c1767f74bf5b94e}{gpuconv1\_\-exec} (\hyperlink{structgpuconv1}{gpuconv1} $\ast$plan, float $\ast$source, float $\ast$dest)
\item 
void \hyperlink{gpuconv1_8h_a12881e4a6e9084e39d1b212117ee4960}{gpuconv1\_\-loadkernel} (\hyperlink{structgpuconv1}{gpuconv1} $\ast$plan, \hyperlink{structtensor}{tensor} $\ast$kernel)
\item 
void \hyperlink{gpuconv1_8h_a35f8f2c7387627d4899dbf8f646ee7cd}{memcpy\_\-r2c} (float $\ast$source, float $\ast$dest, int nReal)
\item 
void \hyperlink{gpuconv1_8h_a888720082e0c7d901f0380b4ed4cecf7}{gpu\_\-copy\_\-pad\_\-r2c} (float $\ast$source, float $\ast$dest, int \hyperlink{gpufft2__test_8cpp_a1a345a1e634b1d40f23b3333f3696366}{N0}, int \hyperlink{gpufft2__test_8cpp_a5a6a26e0827f9640d2eb7201017f19d7}{N1}, int \hyperlink{gpufft2__test_8cpp_adeea8075a0038c985c63d45161804d60}{N2})
\item 
void \hyperlink{gpuconv1_8h_a182cd4b4ca3e28f96c9911593231afbe}{gpu\_\-copy\_\-unpad\_\-c2r} (float $\ast$source, float $\ast$dest, int \hyperlink{gpufft2__test_8cpp_a1a345a1e634b1d40f23b3333f3696366}{N0}, int \hyperlink{gpufft2__test_8cpp_a5a6a26e0827f9640d2eb7201017f19d7}{N1}, int \hyperlink{gpufft2__test_8cpp_adeea8075a0038c985c63d45161804d60}{N2})
\item 
void \hyperlink{gpuconv1_8h_a8775b4b22b7f2ec8f85c1e9c3465fa20}{gpu\_\-kernel\_\-mul} (float $\ast$ft\_\-m\_\-i, float $\ast$ft\_\-kernel\_\-comp\_\-ij, float $\ast$ft\_\-h\_\-comp\_\-j, int nRealNumbers)
\end{DoxyCompactItemize}


\subsection{Detailed Description}
This file implements the simplest possible vector convolution plan on the GPU: All FFT's are complex-\/to-\/complex, no advantage is taken from the real input data. The zero's in the padded magnetization buffers are not ignored. The zero's in the micromagnetic kernel are not ignored. No care is taken to align CUDA memory access.

The interface is flexible: gpuconv1\_\-exec(m, h) can be called on any magnetization and field array that match the size of the plan. m and h are thus not stored in the plan itself. This is handy for higher order solvers that keep multiple versions of m and h.

When more intelligent implementations are made, this one can serve as a comparison for correctness and performance.

\begin{DoxySeeAlso}{See also}
\hyperlink{gpuconv1_8h_ac4cd0375594d902676a22b2d24b2d69c}{new\_\-gpuconv1}, \hyperlink{gpuconv1_8h_a290a0200b1639a156c1767f74bf5b94e}{gpuconv1\_\-exec}
\end{DoxySeeAlso}
\begin{DoxyAuthor}{Author}
Arne Vansteenkiste 
\end{DoxyAuthor}


\subsection{Define Documentation}
\hypertarget{gpuconv1_8h_a6ddfdda7a062d10cff4a72b76b44aeb8}{
\index{gpuconv1.h@{gpuconv1.h}!FORWARD@{FORWARD}}
\index{FORWARD@{FORWARD}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{FORWARD}]{\setlength{\rightskip}{0pt plus 5cm}\#define FORWARD~CUFFT\_\-FORWARD}}
\label{gpuconv1_8h_a6ddfdda7a062d10cff4a72b76b44aeb8}
Forward FFT direction. \begin{DoxySeeAlso}{See also}
\hyperlink{gpuconv1_8h_aa6c8d327b2dda097866d1a520ca29845}{gpuc2cplan\_\-exec()} 
\end{DoxySeeAlso}
\hypertarget{gpuconv1_8h_ade269cc47cfaba70068f2586e898051d}{
\index{gpuconv1.h@{gpuconv1.h}!INVERSE@{INVERSE}}
\index{INVERSE@{INVERSE}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{INVERSE}]{\setlength{\rightskip}{0pt plus 5cm}\#define INVERSE~CUFFT\_\-INVERSE}}
\label{gpuconv1_8h_ade269cc47cfaba70068f2586e898051d}
Backward FFT direction. \begin{DoxySeeAlso}{See also}
\hyperlink{gpuconv1_8h_aa6c8d327b2dda097866d1a520ca29845}{gpuc2cplan\_\-exec()} 
\end{DoxySeeAlso}


\subsection{Function Documentation}
\hypertarget{gpuconv1_8h_a2b2b2adffd7de89165c17057066d018a}{
\index{gpuconv1.h@{gpuconv1.h}!delete\_\-gpuc2cplan@{delete\_\-gpuc2cplan}}
\index{delete\_\-gpuc2cplan@{delete\_\-gpuc2cplan}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{delete\_\-gpuc2cplan}]{\setlength{\rightskip}{0pt plus 5cm}void delete\_\-gpuc2cplan ({\bf gpuc2cplan} $\ast$ {\em plan})}}
\label{gpuconv1_8h_a2b2b2adffd7de89165c17057066d018a}
Frees the FFT plan \begin{Desc}
\item[\hyperlink{todo__todo000002}{Todo}]not fully implemented \end{Desc}

\begin{DoxyParams}{Parameters}
\item[{\em plan}]the plan to be deleted \end{DoxyParams}
\hypertarget{gpuconv1_8h_a888720082e0c7d901f0380b4ed4cecf7}{
\index{gpuconv1.h@{gpuconv1.h}!gpu\_\-copy\_\-pad\_\-r2c@{gpu\_\-copy\_\-pad\_\-r2c}}
\index{gpu\_\-copy\_\-pad\_\-r2c@{gpu\_\-copy\_\-pad\_\-r2c}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{gpu\_\-copy\_\-pad\_\-r2c}]{\setlength{\rightskip}{0pt plus 5cm}void gpu\_\-copy\_\-pad\_\-r2c (float $\ast$ {\em source}, \/  float $\ast$ {\em dest}, \/  int {\em N0}, \/  int {\em N1}, \/  int {\em N2})}}
\label{gpuconv1_8h_a888720082e0c7d901f0380b4ed4cecf7}
Copies a field of real numbers into a zero-\/padded array and in the meanwhile converts them to complex format. Runs on the GPU. \begin{DoxySeeAlso}{See also}
\hyperlink{gpuconv1_8h_a182cd4b4ca3e28f96c9911593231afbe}{gpu\_\-copy\_\-unpad\_\-c2r} 
\end{DoxySeeAlso}

\begin{DoxyParams}{Parameters}
\item[{\em source}]real input data, length = N0$\ast$N1$\ast$N2 \item[{\em dest}]complex data destination, length = 2$\ast$N0 $\ast$ 2$\ast$N1 $\ast$ 2$\ast$2$\ast$N2 \item[{\em N0}]X size of the real data \item[{\em N1}]Y size of the real data \item[{\em N2}]Z size of the real data \end{DoxyParams}
\hypertarget{gpuconv1_8h_a182cd4b4ca3e28f96c9911593231afbe}{
\index{gpuconv1.h@{gpuconv1.h}!gpu\_\-copy\_\-unpad\_\-c2r@{gpu\_\-copy\_\-unpad\_\-c2r}}
\index{gpu\_\-copy\_\-unpad\_\-c2r@{gpu\_\-copy\_\-unpad\_\-c2r}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{gpu\_\-copy\_\-unpad\_\-c2r}]{\setlength{\rightskip}{0pt plus 5cm}void gpu\_\-copy\_\-unpad\_\-c2r (float $\ast$ {\em source}, \/  float $\ast$ {\em dest}, \/  int {\em N0}, \/  int {\em N1}, \/  int {\em N2})}}
\label{gpuconv1_8h_a182cd4b4ca3e28f96c9911593231afbe}
Copies the \char`\"{}region of interest\char`\"{} from a zero-\/padded array of complex numbers into a smaller array of real numbers. Drops the imaginary parts on the fly. Runs on the GPU. \begin{DoxySeeAlso}{See also}
\hyperlink{gpuconv1_8h_a888720082e0c7d901f0380b4ed4cecf7}{gpu\_\-copy\_\-pad\_\-r2c} 
\end{DoxySeeAlso}

\begin{DoxyParams}{Parameters}
\item[{\em source}]complex input data, length = 2$\ast$N0 $\ast$ 2$\ast$N1 $\ast$ 2$\ast$2$\ast$N2 \item[{\em dest}]real data destination, length = N0$\ast$N1$\ast$N2 \item[{\em N0}]X size of the real data \item[{\em N1}]X size of the real data \item[{\em N2}]X size of the real data \end{DoxyParams}
\hypertarget{gpuconv1_8h_a8775b4b22b7f2ec8f85c1e9c3465fa20}{
\index{gpuconv1.h@{gpuconv1.h}!gpu\_\-kernel\_\-mul@{gpu\_\-kernel\_\-mul}}
\index{gpu\_\-kernel\_\-mul@{gpu\_\-kernel\_\-mul}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{gpu\_\-kernel\_\-mul}]{\setlength{\rightskip}{0pt plus 5cm}void gpu\_\-kernel\_\-mul (float $\ast$ {\em ft\_\-m\_\-i}, \/  float $\ast$ {\em ft\_\-kernel\_\-comp\_\-ij}, \/  float $\ast$ {\em ft\_\-h\_\-comp\_\-j}, \/  int {\em nRealNumbers})}}
\label{gpuconv1_8h_a8775b4b22b7f2ec8f85c1e9c3465fa20}
Pointwise multiplication of arrays of complex numbers. ft\_\-h\_\-comp\_\-j += ft\_\-m\_\-i $\ast$ ft\_\-kernel\_\-comp\_\-ij. Runs on the GPU. \begin{Desc}
\item[\hyperlink{todo__todo000004}{Todo}]make use of symmetry \end{Desc}
\begin{DoxyNote}{Note}
DO NOT store in texture memory! This would be a bit faster on older devices, but actually slower on Fermi cards! 
\end{DoxyNote}

\begin{DoxyParams}{Parameters}
\item[{\em ft\_\-m\_\-i}]multiplication input 1 \item[{\em ft\_\-kernel\_\-comp\_\-ij}]multiplication input 2 \item[{\em ft\_\-h\_\-comp\_\-j}]multiplication result gets added to this array \item[{\em nRealNumbers}]the number of floats(!) in each of the arrays, thus twice the number of complex's in them. \end{DoxyParams}
\hypertarget{gpuconv1_8h_aa6c8d327b2dda097866d1a520ca29845}{
\index{gpuconv1.h@{gpuconv1.h}!gpuc2cplan\_\-exec@{gpuc2cplan\_\-exec}}
\index{gpuc2cplan\_\-exec@{gpuc2cplan\_\-exec}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{gpuc2cplan\_\-exec}]{\setlength{\rightskip}{0pt plus 5cm}void gpuc2cplan\_\-exec ({\bf gpuc2cplan} $\ast$ {\em plan}, \/  float $\ast$ {\em data}, \/  int {\em direction})}}
\label{gpuconv1_8h_aa6c8d327b2dda097866d1a520ca29845}
Executes the 3D complex-\/to-\/complex FFT plan in-\/place. 
\begin{DoxyParams}{Parameters}
\item[{\em plan}]the plan to be executed \item[{\em data}]data to be transformed in-\/place \item[{\em direction}]FORWARD or INVERSE \end{DoxyParams}
\hypertarget{gpuconv1_8h_a290a0200b1639a156c1767f74bf5b94e}{
\index{gpuconv1.h@{gpuconv1.h}!gpuconv1\_\-exec@{gpuconv1\_\-exec}}
\index{gpuconv1\_\-exec@{gpuconv1\_\-exec}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{gpuconv1\_\-exec}]{\setlength{\rightskip}{0pt plus 5cm}void gpuconv1\_\-exec ({\bf gpuconv1} $\ast$ {\em plan}, \/  float $\ast$ {\em source}, \/  float $\ast$ {\em dest})}}
\label{gpuconv1_8h_a290a0200b1639a156c1767f74bf5b94e}
Executes the convolution plan: convolves the source data with the stored kernel and stores the result in the destination pointer. \begin{Desc}
\item[\hyperlink{todo__todo000003}{Todo}]: rename: execute \end{Desc}

\begin{DoxyParams}{Parameters}
\item[{\em plan}]the plan to execute \item[{\em source}]the input vector field (magnetization) \item[{\em dest}]the destination vector field (magnetic field) to store the result in \end{DoxyParams}
\hypertarget{gpuconv1_8h_a12881e4a6e9084e39d1b212117ee4960}{
\index{gpuconv1.h@{gpuconv1.h}!gpuconv1\_\-loadkernel@{gpuconv1\_\-loadkernel}}
\index{gpuconv1\_\-loadkernel@{gpuconv1\_\-loadkernel}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{gpuconv1\_\-loadkernel}]{\setlength{\rightskip}{0pt plus 5cm}void gpuconv1\_\-loadkernel ({\bf gpuconv1} $\ast$ {\em plan}, \/  {\bf tensor} $\ast$ {\em kernel})}}
\label{gpuconv1_8h_a12881e4a6e9084e39d1b212117ee4960}
Loads a kernel. Automatically called during \hyperlink{gpuconv1_8h_ac4cd0375594d902676a22b2d24b2d69c}{new\_\-gpuconv1()}, but could be used to change the kernel afterwards. \begin{DoxySeeAlso}{See also}
\hyperlink{gpuconv1_8h_ac4cd0375594d902676a22b2d24b2d69c}{new\_\-gpuconv1} 
\end{DoxySeeAlso}

\begin{DoxyParams}{Parameters}
\item[{\em plan}]plan to load the kernel into \item[{\em kernel}]kernel to load (should match the plan size) \end{DoxyParams}
\hypertarget{gpuconv1_8h_a35f8f2c7387627d4899dbf8f646ee7cd}{
\index{gpuconv1.h@{gpuconv1.h}!memcpy\_\-r2c@{memcpy\_\-r2c}}
\index{memcpy\_\-r2c@{memcpy\_\-r2c}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{memcpy\_\-r2c}]{\setlength{\rightskip}{0pt plus 5cm}void memcpy\_\-r2c (float $\ast$ {\em source}, \/  float $\ast$ {\em dest}, \/  int {\em nReal})}}
\label{gpuconv1_8h_a35f8f2c7387627d4899dbf8f646ee7cd}
Copies a real array to an array of complex numbers (of twice the size) and interleaves the elements with zero's (imaginary parts). \hypertarget{gpuconv1_8h_a7f9fff8937542904f3822c36dc968519}{
\index{gpuconv1.h@{gpuconv1.h}!new\_\-gpuc2cplan@{new\_\-gpuc2cplan}}
\index{new\_\-gpuc2cplan@{new\_\-gpuc2cplan}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{new\_\-gpuc2cplan}]{\setlength{\rightskip}{0pt plus 5cm}{\bf gpuc2cplan}$\ast$ new\_\-gpuc2cplan (int {\em N0}, \/  int {\em N1}, \/  int {\em N2})}}
\label{gpuconv1_8h_a7f9fff8937542904f3822c36dc968519}
Creates a new 3D complex-\/to-\/complex FFT plan for the GPU. \begin{Desc}
\item[\hyperlink{todo__todo000001}{Todo}]There is a difficulty with real-\/to-\/complex FFT's: the last dimension must be made 2 complex numbers larger, but then it does not fit the stride anymore. Extra padding? Out-\/of-\/place transform? \end{Desc}

\begin{DoxyParams}{Parameters}
\item[{\em N0}]size in x-\/direction \item[{\em N1}]size in y-\/direction \item[{\em N2}]size in z-\/direction \end{DoxyParams}
\hypertarget{gpuconv1_8h_ac4cd0375594d902676a22b2d24b2d69c}{
\index{gpuconv1.h@{gpuconv1.h}!new\_\-gpuconv1@{new\_\-gpuconv1}}
\index{new\_\-gpuconv1@{new\_\-gpuconv1}!gpuconv1.h@{gpuconv1.h}}
\subsubsection[{new\_\-gpuconv1}]{\setlength{\rightskip}{0pt plus 5cm}{\bf gpuconv1}$\ast$ new\_\-gpuconv1 (int {\em N0}, \/  int {\em N1}, \/  int {\em N2}, \/  {\bf tensor} $\ast$ {\em kernel})}}
\label{gpuconv1_8h_ac4cd0375594d902676a22b2d24b2d69c}
New convolution plan. 
\begin{DoxyParams}{Parameters}
\item[{\em N0}]X size of the magnetization vector field \item[{\em N1}]Y size of the magnetization vector field \item[{\em N2}]Z size of the magnetization vector field \item[{\em kernel}]convolution kernel of size 3 x 3 x 2$\ast$N0 x 2$\ast$N1 x 2$\ast$N2 \end{DoxyParams}
