\hypertarget{structgpuconv2}{
\section{gpuconv2 Struct Reference}
\label{structgpuconv2}\index{gpuconv2@{gpuconv2}}
}


{\ttfamily \#include $<$gpuconv2.h$>$}

\subsection*{Data Fields}
\begin{DoxyCompactItemize}
\item 
\hyperlink{structgpuFFT3dPlan}{gpuFFT3dPlan} $\ast$ \hyperlink{structgpuconv2_adcd4ad6d8d98a95c99e698415a3cc058}{fftplan}
\item 
\hyperlink{structtensor}{tensor} $\ast$ \hyperlink{structgpuconv2_a1dcf396307b4b1787d139c2f7707a267}{m}
\begin{DoxyCompactList}\small\item\em no space is allocated for m, this is just a pointer the m being convolved at the moment. It's mainly used to store the size of m. \item\end{DoxyCompactList}\item 
\hyperlink{structtensor}{tensor} $\ast$ \hyperlink{structgpuconv2_acdabd23ef571842ec90007196a2e0d17}{mComp} \mbox{[}3\mbox{]}
\begin{DoxyCompactList}\small\item\em points to mx, my, mz. again, no space is allocated as this just points into m. each time m-\/$>$list is set, mComp needs to be updated as well... \item\end{DoxyCompactList}\item 
\hyperlink{structtensor}{tensor} $\ast$ \hyperlink{structgpuconv2_ae55b0700d3d86df36914b511fcaa25a0}{h}
\begin{DoxyCompactList}\small\item\em no space is allocated for h, this is just a pointer the h being convolved at the moment. It's mainly used to store the size of h. \item\end{DoxyCompactList}\item 
\hyperlink{structtensor}{tensor} $\ast$ \hyperlink{structgpuconv2_a49eb6e78bd054b216c5d88a960eecf77}{hComp} \mbox{[}3\mbox{]}
\begin{DoxyCompactList}\small\item\em points to hx, hy, hz. again, no space is allocated as this just points into h. each time h-\/$>$list is set, hComp needs to be updated as well... \item\end{DoxyCompactList}\item 
int $\ast$ \hyperlink{structgpuconv2_aebc50066934a168c5a1a90f550bd7a84}{paddedSize}
\begin{DoxyCompactList}\small\item\em logical size of the zero-\/padded data. No tensor actually has this size: fftXComp has about paddedSize, but plus one stride in the Z dimension. \item\end{DoxyCompactList}\item 
\hyperlink{structtensor}{tensor} $\ast$ \hyperlink{structgpuconv2_adfe815ea2f0f1bc3fcc9253b0bf7769f}{fft1}
\begin{DoxyCompactList}\small\item\em buffer to store and transform the zero-\/padded magnetization and field \item\end{DoxyCompactList}\item 
\hyperlink{structtensor}{tensor} $\ast$ \hyperlink{structgpuconv2_aa04ceddba4c4ec6d485fcc1df2545a6a}{fft1Comp} \mbox{[}3\mbox{]}
\item 
\hyperlink{structtensor}{tensor} $\ast$ \hyperlink{structgpuconv2_afa4419639a375a47f5665586401ae8cc}{fft2}
\begin{DoxyCompactList}\small\item\em second fft buffer. By default, this one points to fft1, so everything is in-\/place. However, it can also be separatly allocated so that the FFT's \item\end{DoxyCompactList}\item 
\hyperlink{structtensor}{tensor} $\ast$ \hyperlink{structgpuconv2_ae20f81460c1c8355a7af279f9c660468}{fft2Comp} \mbox{[}3\mbox{]}
\item 
\hyperlink{structtensor}{tensor} $\ast$ \hyperlink{structgpuconv2_a2f94841448d094437cccceaf0b468bdc}{fftKernel} \mbox{[}3\mbox{]}\mbox{[}3\mbox{]}
\begin{DoxyCompactList}\small\item\em not stored as a rank 5 kernel because the underlying storage is not neccessarily contiguous: we can exploit the kernel symmetry and make K\mbox{[}X\mbox{]}\mbox{[}Y\mbox{]} point to K\mbox{[}Y\mbox{]}\mbox{[}X\mbox{]}, etc. \item\end{DoxyCompactList}\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyInternal}{For internal use only.}
\end{DoxyInternal}


\subsection{Field Documentation}
\hypertarget{structgpuconv2_adfe815ea2f0f1bc3fcc9253b0bf7769f}{
\index{gpuconv2@{gpuconv2}!fft1@{fft1}}
\index{fft1@{fft1}!gpuconv2@{gpuconv2}}
\subsubsection[{fft1}]{\setlength{\rightskip}{0pt plus 5cm}{\bf tensor}$\ast$ {\bf gpuconv2::fft1}}}
\label{structgpuconv2_adfe815ea2f0f1bc3fcc9253b0bf7769f}


buffer to store and transform the zero-\/padded magnetization and field 

\hypertarget{structgpuconv2_aa04ceddba4c4ec6d485fcc1df2545a6a}{
\index{gpuconv2@{gpuconv2}!fft1Comp@{fft1Comp}}
\index{fft1Comp@{fft1Comp}!gpuconv2@{gpuconv2}}
\subsubsection[{fft1Comp}]{\setlength{\rightskip}{0pt plus 5cm}{\bf tensor}$\ast$ {\bf gpuconv2::fft1Comp}\mbox{[}3\mbox{]}}}
\label{structgpuconv2_aa04ceddba4c4ec6d485fcc1df2545a6a}
\hypertarget{structgpuconv2_afa4419639a375a47f5665586401ae8cc}{
\index{gpuconv2@{gpuconv2}!fft2@{fft2}}
\index{fft2@{fft2}!gpuconv2@{gpuconv2}}
\subsubsection[{fft2}]{\setlength{\rightskip}{0pt plus 5cm}{\bf tensor}$\ast$ {\bf gpuconv2::fft2}}}
\label{structgpuconv2_afa4419639a375a47f5665586401ae8cc}


second fft buffer. By default, this one points to fft1, so everything is in-\/place. However, it can also be separatly allocated so that the FFT's 

\hypertarget{structgpuconv2_ae20f81460c1c8355a7af279f9c660468}{
\index{gpuconv2@{gpuconv2}!fft2Comp@{fft2Comp}}
\index{fft2Comp@{fft2Comp}!gpuconv2@{gpuconv2}}
\subsubsection[{fft2Comp}]{\setlength{\rightskip}{0pt plus 5cm}{\bf tensor}$\ast$ {\bf gpuconv2::fft2Comp}\mbox{[}3\mbox{]}}}
\label{structgpuconv2_ae20f81460c1c8355a7af279f9c660468}
\hypertarget{structgpuconv2_a2f94841448d094437cccceaf0b468bdc}{
\index{gpuconv2@{gpuconv2}!fftKernel@{fftKernel}}
\index{fftKernel@{fftKernel}!gpuconv2@{gpuconv2}}
\subsubsection[{fftKernel}]{\setlength{\rightskip}{0pt plus 5cm}{\bf tensor}$\ast$ {\bf gpuconv2::fftKernel}\mbox{[}3\mbox{]}\mbox{[}3\mbox{]}}}
\label{structgpuconv2_a2f94841448d094437cccceaf0b468bdc}


not stored as a rank 5 kernel because the underlying storage is not neccessarily contiguous: we can exploit the kernel symmetry and make K\mbox{[}X\mbox{]}\mbox{[}Y\mbox{]} point to K\mbox{[}Y\mbox{]}\mbox{[}X\mbox{]}, etc. 

\hypertarget{structgpuconv2_adcd4ad6d8d98a95c99e698415a3cc058}{
\index{gpuconv2@{gpuconv2}!fftplan@{fftplan}}
\index{fftplan@{fftplan}!gpuconv2@{gpuconv2}}
\subsubsection[{fftplan}]{\setlength{\rightskip}{0pt plus 5cm}{\bf gpuFFT3dPlan}$\ast$ {\bf gpuconv2::fftplan}}}
\label{structgpuconv2_adcd4ad6d8d98a95c99e698415a3cc058}
\hypertarget{structgpuconv2_ae55b0700d3d86df36914b511fcaa25a0}{
\index{gpuconv2@{gpuconv2}!h@{h}}
\index{h@{h}!gpuconv2@{gpuconv2}}
\subsubsection[{h}]{\setlength{\rightskip}{0pt plus 5cm}{\bf tensor}$\ast$ {\bf gpuconv2::h}}}
\label{structgpuconv2_ae55b0700d3d86df36914b511fcaa25a0}


no space is allocated for h, this is just a pointer the h being convolved at the moment. It's mainly used to store the size of h. 

\hypertarget{structgpuconv2_a49eb6e78bd054b216c5d88a960eecf77}{
\index{gpuconv2@{gpuconv2}!hComp@{hComp}}
\index{hComp@{hComp}!gpuconv2@{gpuconv2}}
\subsubsection[{hComp}]{\setlength{\rightskip}{0pt plus 5cm}{\bf tensor}$\ast$ {\bf gpuconv2::hComp}\mbox{[}3\mbox{]}}}
\label{structgpuconv2_a49eb6e78bd054b216c5d88a960eecf77}


points to hx, hy, hz. again, no space is allocated as this just points into h. each time h-\/$>$list is set, hComp needs to be updated as well... 

\hypertarget{structgpuconv2_a1dcf396307b4b1787d139c2f7707a267}{
\index{gpuconv2@{gpuconv2}!m@{m}}
\index{m@{m}!gpuconv2@{gpuconv2}}
\subsubsection[{m}]{\setlength{\rightskip}{0pt plus 5cm}{\bf tensor}$\ast$ {\bf gpuconv2::m}}}
\label{structgpuconv2_a1dcf396307b4b1787d139c2f7707a267}


no space is allocated for m, this is just a pointer the m being convolved at the moment. It's mainly used to store the size of m. 

\hypertarget{structgpuconv2_acdabd23ef571842ec90007196a2e0d17}{
\index{gpuconv2@{gpuconv2}!mComp@{mComp}}
\index{mComp@{mComp}!gpuconv2@{gpuconv2}}
\subsubsection[{mComp}]{\setlength{\rightskip}{0pt plus 5cm}{\bf tensor}$\ast$ {\bf gpuconv2::mComp}\mbox{[}3\mbox{]}}}
\label{structgpuconv2_acdabd23ef571842ec90007196a2e0d17}


points to mx, my, mz. again, no space is allocated as this just points into m. each time m-\/$>$list is set, mComp needs to be updated as well... 

\hypertarget{structgpuconv2_aebc50066934a168c5a1a90f550bd7a84}{
\index{gpuconv2@{gpuconv2}!paddedSize@{paddedSize}}
\index{paddedSize@{paddedSize}!gpuconv2@{gpuconv2}}
\subsubsection[{paddedSize}]{\setlength{\rightskip}{0pt plus 5cm}int$\ast$ {\bf gpuconv2::paddedSize}}}
\label{structgpuconv2_aebc50066934a168c5a1a90f550bd7a84}


logical size of the zero-\/padded data. No tensor actually has this size: fftXComp has about paddedSize, but plus one stride in the Z dimension. 



The documentation for this struct was generated from the following file:\begin{DoxyCompactItemize}
\item 
\hyperlink{gpuconv2_8h}{gpuconv2.h}\end{DoxyCompactItemize}
