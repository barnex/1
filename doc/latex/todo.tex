\label{todo__todo000002}
\hypertarget{todo__todo000002}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gpuconv1_8h_a2b2b2adffd7de89165c17057066d018a}{delete\_\-gpuc2cplan}(\hyperlink{structgpuc2cplan}{gpuc2cplan} $\ast$plan) ]not fully implemented 
\end{DoxyDescription}

\label{todo__todo000020}
\hypertarget{todo__todo000020}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{param_8h_a267a1984bde484c0a264696bfa6cb6e2}{delete\_\-param}(param $\ast$p) ]implement 
\end{DoxyDescription}

\label{todo__todo000004}
\hypertarget{todo__todo000004}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gpuconv1_8h_a8775b4b22b7f2ec8f85c1e9c3465fa20}{gpu\_\-kernel\_\-mul}(float $\ast$ft\_\-m\_\-i, float $\ast$ft\_\-kernel\_\-comp\_\-ij, float $\ast$ft\_\-h\_\-comp\_\-j, int nRealNumbers) ]make use of symmetry 
\end{DoxyDescription}

\label{todo__todo000018}
\hypertarget{todo__todo000018}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gputil_8h_ade18ea7bbea940fcdc15c47f6d05b3e7}{gpu\_\-stride\_\-float}() ]use cudaGetDeviceProperties for this? 
\end{DoxyDescription}

\label{todo__todo000012}
\hypertarget{todo__todo000012}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gpufft_8h_a8ef8d9e973c51c2245ef0bdf83088818}{gpu\_\-transposeXZ\_\-complex\_\-inplace}(float $\ast$source, int N0, int N1, int N2) ]does not yet seem to work 
\end{DoxyDescription}

\label{todo__todo000011}
\hypertarget{todo__todo000011}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gpufft_8h_a4180e192ed898bac1a64e7bd95668e5c}{gpu\_\-transposeYZ\_\-complex\_\-inplace}(float $\ast$source, int N0, int N1, int N2) ]does not yet seem to work 
\end{DoxyDescription}

\label{todo__todo000005}
\hypertarget{todo__todo000005}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{structgpuconv1_ad52d94894299e1553a8c8642be29172a}{gpuconv1::h\_\-comp} ]should be removed as it gets only initialized after calling \hyperlink{gpuconv1_8h_a290a0200b1639a156c1767f74bf5b94e}{gpuconv1\_\-exec()}. This is confusing... 
\end{DoxyDescription}

\label{todo__todo000003}
\hypertarget{todo__todo000003}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gpuconv1_8h_a290a0200b1639a156c1767f74bf5b94e}{gpuconv1\_\-exec}(\hyperlink{structgpuconv1}{gpuconv1} $\ast$plan, float $\ast$source, float $\ast$dest) ]: rename: execute 
\end{DoxyDescription}

\label{todo__todo000006}
\hypertarget{todo__todo000006}{}
 
\begin{DoxyDescription}
\item[File \hyperlink{gpuconv2_8h}{gpuconv2.h} ]TODO voor convolutie (Ben)



when NO=1, gxy and gxz are zero


\end{DoxyDescription}

\label{todo__todo000008}
\hypertarget{todo__todo000008}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gpuconv2_8h_a9846e091be7ddd707f1325cd50d0c455}{gpuconv2\_\-loadkernel2DSymm}(\hyperlink{structgpuconv2}{gpuconv2} $\ast$conv, tensor $\ast$kernel2D) ]not yet implemented 
\end{DoxyDescription}

\label{todo__todo000009}
\hypertarget{todo__todo000009}{}
 
\begin{DoxyDescription}
\item[File \hyperlink{gpufft_8h}{gpufft.h} ]In place transpose routines 

Option for out-\/of place transforms 

Accecpt tensor arguments


\end{DoxyDescription}

\label{todo__todo000013}
\hypertarget{todo__todo000013}{}
 
\begin{DoxyDescription}
\item[File \hyperlink{gpufft2_8h}{gpufft2.h} ]In place transpose routines: swap if sourceIndex $>$ destIndex 

Option for out-\/of place transforms 

normalization\_\-factor();


\end{DoxyDescription}

\label{todo__todo000015}
\hypertarget{todo__todo000015}{}
 
\begin{DoxyDescription}
\item[File \hyperlink{gpurk4_8h}{gpurk4.h} ]we do not need 4 k arrays: just one where we accumulate the total k first calc k\_\-i in shared memory, use it to set the next m\_\-i+1 then add it to the global k array with the correct weigth the last k\_\-i is not even added to that array but immediately to m


\end{DoxyDescription}

\label{todo__todo000016}
\hypertarget{todo__todo000016}{}
 
\begin{DoxyDescription}
\item[File \hyperlink{gputil_8h}{gputil.h} ]use CudaGetDeviceProperties to obtain the maximum number of threads per block, etc... 

Strided Arrays 

Smart zero-\/padded FFT's: try strided and transposed 

choose between in-\/place and out-\/of-\/place FFT's for best performance or best memory efficiency


\end{DoxyDescription}

\label{todo__todo000019}
\hypertarget{todo__todo000019}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gputil_8h_a5f10ebe67635ce652fa229fa9d8ebc78}{make3dconf}(int N0, int N1, int N2, dim3 $\ast$gridSize, dim3 $\ast$blockSize) ]works only up to N2 = 512 
\end{DoxyDescription}

\label{todo__todo000010}
\hypertarget{todo__todo000010}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gpufft_8h_adaab760b0595a368b478605477bb9e2d}{new\_\-gpu\_\-plan3d\_\-real\_\-input}(int N0, int N1, int N2, int $\ast$zero\_\-pad) ]on compute capability $<$ 2.0, the first step is done serially... 
\end{DoxyDescription}

\label{todo__todo000001}
\hypertarget{todo__todo000001}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gpuconv1_8h_a7f9fff8937542904f3822c36dc968519}{new\_\-gpuc2cplan}(int N0, int N1, int N2) ]There is a difficulty with real-\/to-\/complex FFT's: the last dimension must be made 2 complex numbers larger, but then it does not fit the stride anymore. Extra padding? Out-\/of-\/place transform? 
\end{DoxyDescription}

\label{todo__todo000014}
\hypertarget{todo__todo000014}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gpufft2_8h_a56fef026d295e4997387d2a5003280bf}{new\_\-gpuFFT3dPlan\_\-padded}(int $\ast$size, int $\ast$paddedsize) ]: better give paddedstoragesize? is less confusing. 
\end{DoxyDescription}

\label{todo__todo000017}
\hypertarget{todo__todo000017}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{gputil_8h_a7c2b7f29fd636e841b2001b07ffb5d18}{new\_\-gputensor}(int rank, int $\ast$size) ]delete\_\-gputensor() 
\end{DoxyDescription}

\label{todo__todo000021}
\hypertarget{todo__todo000021}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{structparam_a7274904db5b3421e22e323af7d1d7563}{param::exchType} ]add demag kernel here too? 
\end{DoxyDescription}

\label{todo__todo000022}
\hypertarget{todo__todo000022}{}
 
\begin{DoxyDescription}
\item[Global \hyperlink{pipes_8h_a03c86bf04106660fa2a7592726f07c19}{pipe\_\-tensor}(char $\ast$command) ]error handling 
\end{DoxyDescription}

\label{todo__todo000023}
\hypertarget{todo__todo000023}{}
 
\begin{DoxyDescription}
\item[File \hyperlink{pipes_8h}{pipes.h} ]pipe\_\-kernel(msat, aexch, size, ...) to get a micromagnetic kernel 

pipe\_\-config() for an initial configuration 

pipe\_\-output() for post-\/processing


\end{DoxyDescription}

\label{todo__todo000024}
\hypertarget{todo__todo000024}{}
 
\begin{DoxyDescription}
\item[File \hyperlink{tensor_8h}{tensor.h} ]-\/$>$array (void$\ast$) 

-\/$>$gpu? 

remove variadic functions, they sometimes give problems.


\end{DoxyDescription}