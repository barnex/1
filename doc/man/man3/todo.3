.TH "todo" 3 "6 Jul 2010" "GPU_simulations" \" -*- nroff -*-
.ad l
.nh
.SH NAME
todo \- Todo List 
 
.IP "\fBGlobal \fBdelete_gpuc2cplan\fP(\fBgpuc2cplan\fP *plan) \fP" 1c
not fully implemented 
.PP
.PP
 
.IP "\fBGlobal \fBdelete_param\fP(param *p) \fP" 1c
implement 
.PP
.PP
 
.IP "\fBGlobal \fBgpu_kernel_mul\fP(float *ft_m_i, float *ft_kernel_comp_ij, float *ft_h_comp_j, int nRealNumbers) \fP" 1c
make use of symmetry 
.PP
.PP
 
.IP "\fBGlobal \fBgpu_stride_float\fP() \fP" 1c
use cudaGetDeviceProperties for this? 
.PP
.PP
 
.IP "\fBGlobal \fBgpu_transposeXZ_complex_inplace\fP(float *source, int N0, int N1, int N2) \fP" 1c
does not yet seem to work 
.PP
.PP
 
.IP "\fBGlobal \fBgpu_transposeYZ_complex_inplace\fP(float *source, int N0, int N1, int N2) \fP" 1c
does not yet seem to work 
.PP
.PP
 
.IP "\fBGlobal \fBgpuconv1::h_comp\fP \fP" 1c
should be removed as it gets only initialized after calling \fBgpuconv1_exec()\fP. This is confusing... 
.PP
.PP
 
.IP "\fBGlobal \fBgpuconv1_exec\fP(\fBgpuconv1\fP *plan, float *source, float *dest) \fP" 1c
: rename: execute 
.PP
.PP
 
.IP "\fBFile \fBgpuconv2.h\fP \fP" 1c
TODO voor convolutie (Ben)
.PP
.PP
when NO=1, gxy and gxz are zero
.PP
.PP
.PP
 
.IP "\fBGlobal \fBgpuconv2_loadkernel2DSymm\fP(\fBgpuconv2\fP *conv, tensor *kernel2D) \fP" 1c
not yet implemented 
.PP
.PP
 
.IP "\fBFile \fBgpufft.h\fP \fP" 1c
In place transpose routines 
.PP
Option for out-of place transforms 
.PP
Accecpt tensor arguments
.PP
.PP
.PP
 
.IP "\fBFile \fBgpufft2.h\fP \fP" 1c
In place transpose routines: swap if sourceIndex > destIndex 
.PP
Option for out-of place transforms 
.PP
normalization_factor();
.PP
.PP
.PP
 
.IP "\fBFile \fBgpurk4.h\fP \fP" 1c
we do not need 4 k arrays: just one where we accumulate the total k first calc k_i in shared memory, use it to set the next m_i+1 then add it to the global k array with the correct weigth the last k_i is not even added to that array but immediately to m
.PP
.PP
.PP
 
.IP "\fBFile \fBgputil.h\fP \fP" 1c
use CudaGetDeviceProperties to obtain the maximum number of threads per block, etc... 
.PP
Strided Arrays 
.PP
Smart zero-padded FFT's: try strided and transposed 
.PP
choose between in-place and out-of-place FFT's for best performance or best memory efficiency
.PP
.PP
.PP
 
.IP "\fBGlobal \fBmake3dconf\fP(int N0, int N1, int N2, dim3 *gridSize, dim3 *blockSize) \fP" 1c
works only up to N2 = 512 
.PP
.PP
 
.IP "\fBGlobal \fBnew_gpu_plan3d_real_input\fP(int N0, int N1, int N2, int *zero_pad) \fP" 1c
on compute capability < 2.0, the first step is done serially... 
.PP
.PP
 
.IP "\fBGlobal \fBnew_gpuc2cplan\fP(int N0, int N1, int N2) \fP" 1c
There is a difficulty with real-to-complex FFT's: the last dimension must be made 2 complex numbers larger, but then it does not fit the stride anymore. Extra padding? Out-of-place transform? 
.PP
.PP
 
.IP "\fBGlobal \fBnew_gpuFFT3dPlan_padded\fP(int *size, int *paddedsize) \fP" 1c
: better give paddedstoragesize? is less confusing. 
.PP
.PP
 
.IP "\fBGlobal \fBnew_gputensor\fP(int rank, int *size) \fP" 1c
delete_gputensor() 
.PP
.PP
 
.IP "\fBGlobal \fBparam::exchType\fP \fP" 1c
add demag kernel here too? 
.PP
.PP
 
.IP "\fBGlobal \fBpipe_tensor\fP(char *command) \fP" 1c
error handling 
.PP
.PP
 
.IP "\fBFile \fBpipes.h\fP \fP" 1c
pipe_kernel(msat, aexch, size, ...) to get a micromagnetic kernel 
.PP
pipe_config() for an initial configuration 
.PP
pipe_output() for post-processing
.PP
.PP
.PP
 
.IP "\fBFile \fBtensor.h\fP \fP" 1c
->array (void*) 
.PP
->gpu? 
.PP
remove variadic functions, they sometimes give problems.
.PP
.PP

